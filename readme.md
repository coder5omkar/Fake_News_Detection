ğŸ“˜ Fake News Identification
ğŸ¯ Goal
The primary objective of this project is to build a semantic-based classification system that can effectively differentiate between authentic and misleading news articles. By utilizing Word2Vec embeddings, the project focuses on capturing the underlying meanings of the text, which are then analyzed using supervised learning algorithms for classification.

ğŸ¢ Real-World Relevance
With the increasing circulation of fabricated news, there's a growing need for intelligent tools that can automatically detect misinformation. This solution showcases how semantic analysis can assist digital platforms and end users in evaluating the trustworthiness of online content.

ğŸ—‚ï¸ Data Overview
The dataset includes two distinct CSV files:

ğŸ”¹ True.csv â€“ Contains 21,417 samples of verified news articles.

ğŸ”¹ Fake.csv â€“ Contains 23,502 samples of fabricated news stories.

Each record provides:

ğŸ“Œ title: Headline of the news item

ğŸ“Œ text: Full article content

ğŸ“Œ date: Date when the article was published

ğŸ“Š Key Observations
âœ… Authentic Articles: Use formal language, topic-relevant vocabulary, and a coherent structure.

âš ï¸ False Articles: Tend to feature emotionally loaded words, recurring phrases, and a less organized layout. Certain word patterns and expressions are common in deceptive content.

ğŸ“ˆ Visual analyses (like word clouds) confirmed noticeable differences in vocabulary usage between the two categories.

ğŸ”§ Workflow Breakdown
ğŸ§¹ Data Preprocessing
ğŸ”¹ Removal of noise and irrelevant characters

ğŸ”¹ Lemmatization to unify word forms

ğŸ”¹ Focused on extracting nouns via part-of-speech tagging to enhance semantic feature quality

ğŸ§  Feature Construction
ğŸ”¹ Employed pre-trained Word2Vec vectors to encode textual data into dense, meaning-rich formats

ğŸ§ª Classification Models
ğŸ”¹ Logistic Regression

ğŸ”¹ Decision Tree

ğŸ”¹ Random Forest

ğŸ“ Performance Metrics
ğŸ“Š Accuracy on Validation Set: 86.00%

ğŸ“Š Precision: 85.90%

ğŸ“Š Recall: 87.01%

ğŸ“Š F1-Score: 86.45%

ğŸ“„ Evaluation Summary
Class	Precision	Recall	F1-Score	Support
0 (Fake)	0.86	0.85	0.86	73
1 (Real)	0.86	0.87	0.86	77
Overall	0.86	0.86	0.86	150

Macro Average: Precision = 0.86, Recall = 0.86, F1 = 0.86

Weighted Average: Precision = 0.86, Recall = 0.86, F1 = 0.86

ğŸ” Insights
ğŸ”¹ Semantic techniques enhance classification performance and reduce noise.

ğŸ”¹ Pre-trained Word2Vec simplifies feature engineering while improving depth of analysis.

ğŸ”¹ Random Forest consistently outperformed other models in accuracy and F1-score.

ğŸ”¹ This approach provides a practical foundation for scalable misinformation detection tools.

ğŸ”® Enhancements Ahead
ğŸ”¹ Adapt Word2Vec embeddings using domain-specific datasets for improved relevance.

ğŸ”¹ Explore context-aware models like BERT to further capture linguistic nuances and dependencies.

